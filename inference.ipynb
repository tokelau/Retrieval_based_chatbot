{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "bi_model = AutoModel.from_pretrained(\"models/bi_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bi_mean_pool(token_embeds: torch.tensor, attention_mask: torch.tensor) -> torch.tensor:\n",
    "    in_mask = attention_mask.unsqueeze(-1).expand(token_embeds.size()).float()\n",
    "    pool = torch.sum(token_embeds * in_mask, 1) / torch.clamp(in_mask.sum(1), min=1e-9)\n",
    "    return pool\n",
    "\n",
    "\n",
    "def bi_encode(input_texts, tokenizer: AutoTokenizer, model: AutoModel, device: str = \"cpu\"\n",
    ") -> torch.tensor:\n",
    "\n",
    "    model.eval()\n",
    "    tokenized_texts = tokenizer(input_texts, max_length=128,\n",
    "                                padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "    token_embeds = bi_model(tokenized_texts[\"input_ids\"].to(device),\n",
    "                         tokenized_texts[\"attention_mask\"].to(device)).last_hidden_state\n",
    "    pooled_embeds = bi_mean_pool(token_embeds, tokenized_texts[\"attention_mask\"].to(device))\n",
    "    return pooled_embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбор k кандидатов с помощью BI-енкодера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "def get_top_k(query, corpus, top_k=5):\n",
    "    \"\"\"\n",
    "      Выбор k кандидатов. Bi-Encoder\n",
    "    \"\"\"\n",
    "    bi_pooled_embeds = torch.tensor(corpus['pooled_embeds'].apply(json.loads))\n",
    "\n",
    "    bi_pooled_embeds_query = bi_encode(query, tokenizer, bi_model, device)\n",
    "    bi_pooled_embeds_query = bi_pooled_embeds_query.cpu().detach().numpy() \n",
    "\n",
    "    similarities = cosine_similarity(bi_pooled_embeds_query, bi_pooled_embeds)\n",
    "\n",
    "    sim_indexies = np.argsort(similarities)[0, ::-1]\n",
    "    sim_indexies = sim_indexies[:top_k]\n",
    "    return corpus.iloc[sim_indexies], similarities[0, sim_indexies]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подгружаем данные и ищем релевантных кандидатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "house_answers = pd.read_csv('data/house_answers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>line</th>\n",
       "      <th>responder</th>\n",
       "      <th>response</th>\n",
       "      <th>token_embeds</th>\n",
       "      <th>pooled_embeds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James</td>\n",
       "      <td>You can't go in there.</td>\n",
       "      <td>House</td>\n",
       "      <td>Who are you, and why are you wearing a tie?</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.343617707490921, 0.14434118568897247, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>James</td>\n",
       "      <td>I'm Dr. Cuddy's new assistant. Can I tell her...</td>\n",
       "      <td>House</td>\n",
       "      <td>Yes. I would like to know why she gets a secr...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.07738427072763443, -0.024036986753344536, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>James</td>\n",
       "      <td>I'm her assistant, not her secretary. I gradu...</td>\n",
       "      <td>House</td>\n",
       "      <td>Hmm. I didn't know they had a secretarial sch...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.18388719856739044, -0.1642012745141983, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cuddy</td>\n",
       "      <td>Dr. House, we are in the middle of a meeting.</td>\n",
       "      <td>House</td>\n",
       "      <td>What's with hiring a male secretary? JDate no...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.20013472437858582, -0.08547274768352509, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stacy</td>\n",
       "      <td>He is cute. Be careful.</td>\n",
       "      <td>House</td>\n",
       "      <td>She's not like you. She can't just walk into ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.061828095465898514, -0.13099761307239532, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name                                               line responder  \\\n",
       "0  James                             You can't go in there.     House   \n",
       "1  James   I'm Dr. Cuddy's new assistant. Can I tell her...     House   \n",
       "2  James   I'm her assistant, not her secretary. I gradu...     House   \n",
       "3  Cuddy      Dr. House, we are in the middle of a meeting.     House   \n",
       "4  Stacy                            He is cute. Be careful.     House   \n",
       "\n",
       "                                            response  token_embeds  \\\n",
       "0        Who are you, and why are you wearing a tie?             0   \n",
       "1   Yes. I would like to know why she gets a secr...             0   \n",
       "2   Hmm. I didn't know they had a secretarial sch...             0   \n",
       "3   What's with hiring a male secretary? JDate no...             0   \n",
       "4   She's not like you. She can't just walk into ...             0   \n",
       "\n",
       "                                       pooled_embeds  \n",
       "0  [0.343617707490921, 0.14434118568897247, -0.02...  \n",
       "1  [0.07738427072763443, -0.024036986753344536, 0...  \n",
       "2  [0.18388719856739044, -0.1642012745141983, -0....  \n",
       "3  [-0.20013472437858582, -0.08547274768352509, 0...  \n",
       "4  [0.061828095465898514, -0.13099761307239532, 0...  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"You can't go in there.\"\n",
    "candidates = get_top_k(query, house_answers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          name                                         line responder  \\\n",
       " 0        James                       You can't go in there.     House   \n",
       " 15587    Cuddy           You can't ride that thing in here.     House   \n",
       " 12424  Beasley   You can't go up there. It's yard time now.     House   \n",
       " 3310   Cameron            You can't just be walking around.     House   \n",
       " 3786   Cameron                           You can't do that.     House   \n",
       " \n",
       "                                                 response  \\\n",
       " 0            Who are you, and why are you wearing a tie?   \n",
       " 15587   Speaking of things, (He looks through the sta...   \n",
       " 12424                                  Put it on my tab.   \n",
       " 3310                                Well, then, stop me.   \n",
       " 3786    Can't do what? Administer a prescription pain...   \n",
       " \n",
       "                                             token_embeds  \\\n",
       " 0      [[ 0.34750035  0.039516   -0.07297491 ... -0.1...   \n",
       " 15587  [[ 0.18516737  0.18311346 -0.09143019 ... -0.4...   \n",
       " 12424  [[ 0.33136973 -0.00492999  0.27404776 ... -0.1...   \n",
       " 3310   [[ 4.31296647e-01 -8.29652101e-02  1.07492208e...   \n",
       " 3786   [[ 0.38746032  0.15273689 -0.03715749 ... -0.2...   \n",
       " \n",
       "                                            pooled_embeds  \n",
       " 0      [0.343617707490921, 0.14434118568897247, -0.02...  \n",
       " 15587  [0.14739148318767548, 0.24300260841846466, -0....  \n",
       " 12424  [0.056067124009132385, 0.08130894601345062, 0....  \n",
       " 3310   [0.6193155646324158, 0.051403239369392395, 0.3...  \n",
       " 3786   [0.4629920721054077, 0.24348756670951843, 0.15...  ,\n",
       " array([0.99999994, 0.90173656, 0.8947617 , 0.8761934 , 0.87402236],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 128\n",
    "class CrossEncoderBert(torch.nn.Module):\n",
    "    def __init__(self, max_length: int = MAX_LENGTH):\n",
    "        super().__init__()\n",
    "        self.max_length = max_length\n",
    "        self.bert_model = AutoModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.bert_tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "        self.linear = torch.nn.Linear(self.bert_model.config.hidden_size, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]  # Use the CLS token's output\n",
    "        return self.linear(pooled_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEncoderBert(\n",
       "  (bert_model): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_model = CrossEncoderBert()\n",
    "ce_model.load_state_dict(torch.load('models/CE_model', weights_only=True))\n",
    "ce_model.to(device)\n",
    "ce_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranked_docs(\n",
    "    query: str, candidates,\n",
    "    tokenizer: AutoTokenizer, \n",
    "    finetuned_ce: CrossEncoderBert \n",
    ") -> None:\n",
    "    corpus = candidates['line'].to_list()\n",
    "\n",
    "    queries = [query] * len(corpus)\n",
    "    tokenized_texts = tokenizer(\n",
    "        queries, corpus, max_length=MAX_LENGTH, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "    # Finetuned CrossEncoder model scoring\n",
    "    with torch.no_grad():\n",
    "        ce_scores = finetuned_ce(tokenized_texts['input_ids'], tokenized_texts['attention_mask']).squeeze(-1)\n",
    "        ce_scores = torch.sigmoid(ce_scores)  # Apply sigmoid if needed\n",
    "\n",
    "    # Process scores for finetuned model\n",
    "    print(f\"Query - {query} [Finetuned Cross-Encoder]\\n---\")\n",
    "    scores = ce_scores.cpu().numpy()\n",
    "    scores_ix = np.argsort(scores)[::-1]\n",
    "    for ix in scores_ix:  # Limit to corpus size\n",
    "        print(f\"{scores[ix]: >.2f}\\t{corpus[ix]}\")\n",
    "        \n",
    "    return candidates.iloc[scores_ix], scores[scores_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query - You can't go in there. [Finetuned Cross-Encoder]\n",
      "---\n",
      "0.98\t You can't go in there.\n",
      "0.92\t You can't ride that thing in here.\n",
      "0.90\t You can't go up there. It's yard time now.\n",
      "0.90\t You can't do that.\n",
      "0.84\t You can't just be walking around.\n"
     ]
    }
   ],
   "source": [
    "ranked_candidates = get_ranked_docs(query, candidates[0], tokenizer, ce_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(query: str):\n",
    "    candidates = get_top_k(query, house_answers) \n",
    "    ranked_candidate = get_ranked_docs(query, candidates[0], tokenizer, ce_model)\n",
    "    return ranked_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query - hello [Finetuned Cross-Encoder]\n",
      "---\n",
      "0.92\t Hello?\n",
      "0.92\t Hello?\n",
      "0.92\t Hello?\n",
      "0.92\t Hello?\n",
      "0.81\t Hi.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(          name     line responder  \\\n",
       " 9159     Cuddy   Hello?     House   \n",
       " 14994    Chase   Hello?     House   \n",
       " 6117   Cameron   Hello?     House   \n",
       " 2870   Foreman   Hello?     House   \n",
       " 16135     Park      Hi.     House   \n",
       " \n",
       "                                                 response  token_embeds  \\\n",
       " 9159                Don't hang up. What was the verdict?             0   \n",
       " 14994                                              Yeah.             0   \n",
       " 6117                               He's not a sociopath.             0   \n",
       " 2870    [in a hazmat suit on a hands-free phone] I'm ...             0   \n",
       " 16135   I'm not interested in another department's sl...             0   \n",
       " \n",
       "                                            pooled_embeds  \n",
       " 9159   [-0.26658883690834045, -0.49618983268737793, -...  \n",
       " 14994  [-0.26658883690834045, -0.49618983268737793, -...  \n",
       " 6117   [-0.26658883690834045, -0.49618983268737793, -...  \n",
       " 2870   [-0.26658883690834045, -0.49618983268737793, -...  \n",
       " 16135  [0.1605694591999054, -0.8235059976577759, 0.24...  ,\n",
       " array([0.9234985, 0.9234985, 0.9234985, 0.9234985, 0.8057705],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"hello\"\n",
    "get_answer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.10.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /opt/homebrew/lib/python3.11/site-packages (from faiss-cpu) (2.2.3)\n",
      "Requirement already satisfied: packaging in /Users/anastasialobkina/Library/Python/3.11/lib/python/site-packages (from faiss-cpu) (23.0)\n",
      "Downloading faiss_cpu-1.10.0-cp311-cp311-macosx_11_0_arm64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.10.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3.11 install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "index = faiss.IndexFlatIP((768))\n",
    "index.add(torch.tensor(house_answers['pooled_embeds'].apply(json.loads)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_faiss(query: str):\n",
    "    start_time = time.time()\n",
    "    bi_pooled_embeds_query = bi_encode(query, tokenizer, bi_model, device)\n",
    "    bi_pooled_embeds_query = bi_pooled_embeds_query.cpu().detach().numpy() \n",
    "    # candidates = get_top_k(query, house_answers) \n",
    "    candidates = index.search(bi_pooled_embeds_query, k=10)\n",
    "    \n",
    "    print(candidates[1])\n",
    "    candidates = house_answers.iloc[candidates[1][0]]\n",
    "    \n",
    "    ranked_candidate = get_ranked_docs(query, candidates, tokenizer, ce_model)\n",
    "    end_time = time.time() - start_time\n",
    "    return *ranked_candidate, end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0 10405  1633  8123 12501 13547  7608   975 12240 11388]]\n",
      "Query - You can't go in there. [Finetuned Cross-Encoder]\n",
      "---\n",
      "0.98\t You can't go in there.\n",
      "0.93\t You were just in there.\n",
      "0.92\t You can't.\n",
      "0.88\t You're not staying here.\n",
      "0.83\t Don't do this.\n",
      "0.83\t Don't do this.\n",
      "0.83\t Just leave it alone.\n",
      "0.82\t Don't do it.\n",
      "0.80\t You're alone.\n",
      "0.73\t This is not okay. Use your own bathroom.\n",
      "(          name                                       line responder  \\\n",
      "0        James                     You can't go in there.     House   \n",
      "7608    Kutner                    You were just in there.     House   \n",
      "1633   Cameron                                 You can't.     House   \n",
      "10405   Wilson                   You're not staying here.     House   \n",
      "11388    Cuddy                             Don't do this.     House   \n",
      "12240    Amber                             Don't do this.     House   \n",
      "975     Kalvin                       Just leave it alone.     House   \n",
      "12501    Alvie                               Don't do it.     House   \n",
      "8123     Cuddy                              You're alone.     House   \n",
      "13547   Wilson   This is not okay. Use your own bathroom.     House   \n",
      "\n",
      "                                                response  token_embeds  \\\n",
      "0            Who are you, and why are you wearing a tie?             0   \n",
      "7608    Well, apparently, it's impossible to see anyt...             0   \n",
      "1633                 Why? Did he say he doesn't like me?             0   \n",
      "10405                                       Oh, come on.             0   \n",
      "11388   It's already done. (He throws the methadone i...             0   \n",
      "12240                                 I'm hallucinating.             0   \n",
      "975     Just want to leave the bigot with some peace ...             0   \n",
      "12501                            I'm not doing anything.             0   \n",
      "8123    How much more private can you get? [eats some...             0   \n",
      "13547   No canoe in my bathroom. [deep breath] My leg...             0   \n",
      "\n",
      "                                           pooled_embeds  \n",
      "0      [0.343617707490921, 0.14434118568897247, -0.02...  \n",
      "7608   [0.1994393914937973, -0.2097492665052414, 0.31...  \n",
      "1633   [0.6453949809074402, -0.02427510730922222, 0.4...  \n",
      "10405  [0.5766568183898926, -0.02658367156982422, 0.4...  \n",
      "11388  [0.4706963002681732, 0.16558432579040527, 0.00...  \n",
      "12240  [0.4706963002681732, 0.16558432579040527, 0.00...  \n",
      "975    [0.51450514793396, 0.008539238013327122, 0.258...  \n",
      "12501  [0.5191543102264404, 0.027727022767066956, 0.2...  \n",
      "8123   [0.29202359914779663, -0.22402381896972656, 0....  \n",
      "13547  [0.2747822701931, 0.08773566037416458, 0.35823...  , array([0.9794953 , 0.93097925, 0.92452866, 0.87700665, 0.82686025,\n",
      "       0.82686025, 0.8254931 , 0.8209871 , 0.80226946, 0.73318243],\n",
      "      dtype=float32), 0.15618300437927246)\n"
     ]
    }
   ],
   "source": [
    "query = \"You can't go in there.\"\n",
    "# print(get_answer(query))\n",
    "print(get_answer_faiss(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
